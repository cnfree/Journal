# 集群搭建

* 节点不宜过少，需要保证高可用
* 尽量不要用虚拟机，虚拟机无法感知硬盘，有可能一个多份数据跑在同一块硬盘上，导致IO过高，或者硬盘损坏，数据丢失
* 每一台集群节点要保障节点性能参数一致，比如CPU、内存、硬盘、网络等
* 部署集群先要规划好集群节点，比如Job类型、Job任务数，HBase现有容量，Hive容量，HBase表数量，未来每月数据增长量
* HDFS3.0以后不需要每份文件存三份，只需要1.5份做奇偶效验
* Kudu非常耗内存，但千万级数据量用起来比较方便，适合做数仓拉链表，但数据量大的时候不适合
* 实时数据抽取任务需要根据抽取数据量计算内存，最好64G内存
* 数据校验和数据抽取分离，不在同一个任务进

# HBase
* 访问hbase table中的行，只有三种方式：
  1. 通过单个row key访问
  2. 通过row key的range
  3. 全表扫描

* Row key行键 (Row key)可以是任意字符串(最大长度是 64KB，实际应用中长度一般为 10-100bytes)，在hbase内部，row key保存为字节数组。
* 存储时，数据按照Row key的字典序(byte order)排序存储。设计key时，要充分排序存储这个特性，将经常一起读取的行存储放到一起。(位置相关性)
* 字典序对int排序的结果是1,10,100,11,12,13,14,15,16,17,18,19,2,20,21,…,9,91,92,93,94,95,96,97,98,99。要保持整形的自然序，行键必须用0作左填充。 

* HMaster的作用： 
  1. 为Region server分配region。 
  2. 负责Region server的负载均衡。
  3. 发现失效的Region server并重新分配其上的region。
  4. HDFS上的垃圾文件回收。
  5. 处理schema更新请求。

* HRegionServer作用： 
　1. 维护master分配给他的region，处理对这些region的io请求。
  2. 负责切分正在运行过程中变的过大的region。

* client访问hbase上的数据并不需要master参与（寻址访问zookeeper和region server，数据读写访问region server），master仅仅维护table和region的元数据信息（table的元数据信息保存在zookeeper上），负载很低。


# 参考文章
 * [详解HBase架构原理及安装部署步骤] 
 * [HBase系统架构（部署架构）]

[详解HBase架构原理及安装部署步骤]: https://blog.csdn.net/zmx729618/article/details/55045370
[HBase系统架构（部署架构）]: https://blog.csdn.net/f1550804/article/details/88379664
